{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRlg6dtzSHzfRonwKqYWJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Micaiah4data/Amazon_Dashboard/blob/main/Train_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Path to the uploaded files, typically in the current directory\n",
        "folder_path = '/content/ProGan'\n",
        "if folder_path not in sys.path:\n",
        "    sys.path.append(folder_path)\n",
        "\n",
        "# Your training code here\n",
        "\"\"\" Training of ProGAN using WGAN-GP loss\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from utils import (\n",
        "    gradient_penalty,\n",
        "    plot_to_tensorboard,\n",
        "    save_checkpoint,\n",
        "    load_checkpoint,\n",
        "    generate_examples,\n",
        ")\n",
        "from model import Discriminator, Generator\n",
        "from math import log2\n",
        "from tqdm import tqdm\n",
        "import config\n",
        "\n",
        "torch.backends.cudnn.benchmarks = True\n",
        "\n",
        "\n",
        "def get_loader(image_size):\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.Normalize(\n",
        "                [0.5 for _ in range(config.CHANNELS_IMG)],\n",
        "                [0.5 for _ in range(config.CHANNELS_IMG)],\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    batch_size = config.BATCH_SIZES[int(log2(image_size / 4))]\n",
        "    dataset = datasets.ImageFolder(root=config.DATASET, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    return loader, dataset\n",
        "\n",
        "\n",
        "def train_fn(\n",
        "        critic,\n",
        "        gen,\n",
        "        loader,\n",
        "        dataset,\n",
        "        step,\n",
        "        alpha,\n",
        "        opt_critic,\n",
        "        opt_gen,\n",
        "        tensorboard_step,\n",
        "        writer,\n",
        "        scaler_gen,\n",
        "        scaler_critic,\n",
        "):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, (real, _) in enumerate(loop):\n",
        "        real = real.to(config.DEVICE)\n",
        "        cur_batch_size = real.shape[0]\n",
        "\n",
        "        # Train Critic: max E[critic(real)] - E[critic(fake)] <-> min -E[critic(real)] + E[critic(fake)]\n",
        "        # which is equivalent to minimizing the negative of the expression\n",
        "        noise = torch.randn(cur_batch_size, config.Z_DIM, 1, 1).to(config.DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, alpha, step)\n",
        "            critic_real = critic(real, alpha, step)\n",
        "            critic_fake = critic(fake.detach(), alpha, step)\n",
        "            gp = gradient_penalty(critic, real, fake, alpha, step, device=config.DEVICE)\n",
        "            loss_critic = (\n",
        "                    -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
        "                    + config.LAMBDA_GP * gp\n",
        "                    + (0.001 * torch.mean(critic_real ** 2))\n",
        "            )\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, alpha, step)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        # Update alpha and ensure less than 1\n",
        "        alpha += cur_batch_size / (\n",
        "                (config.PROGRESSIVE_EPOCHS[step] * 0.5) * len(dataset)\n",
        "        )\n",
        "        alpha = min(alpha, 1)\n",
        "\n",
        "        if batch_idx % 500 == 0:\n",
        "            with torch.no_grad():\n",
        "                fixed_fakes = gen(config.FIXED_NOISE, alpha, step) * 0.5 + 0.5\n",
        "            plot_to_tensorboard(\n",
        "                writer,\n",
        "                loss_critic.item(),\n",
        "                loss_gen.item(),\n",
        "                real.detach(),\n",
        "                fixed_fakes.detach(),\n",
        "                tensorboard_step,\n",
        "            )\n",
        "            tensorboard_step += 1\n",
        "\n",
        "        loop.set_postfix(\n",
        "            gp=gp.item(),\n",
        "            loss_critic=loss_critic.item(),\n",
        "        )\n",
        "\n",
        "    return tensorboard_step, alpha\n",
        "\n",
        "\n",
        "def main():\n",
        "    # initialize gen and disc, note: discriminator should be called critic,\n",
        "    # according to WGAN paper (since it no longer outputs between [0, 1])\n",
        "    # but really who cares..\n",
        "    gen = Generator(\n",
        "        config.Z_DIM, config.IN_CHANNELS, img_channels=config.CHANNELS_IMG\n",
        "    ).to(config.DEVICE)\n",
        "    critic = Discriminator(\n",
        "        config.Z_DIM, config.IN_CHANNELS, img_channels=config.CHANNELS_IMG\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    # initialize optimizers and scales for FP16 training\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.99))\n",
        "    opt_critic = optim.Adam(\n",
        "        critic.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.99)\n",
        "    )\n",
        "    scaler_critic = torch.cuda.amp.GradScaler()\n",
        "    scaler_gen = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # for tensorboard plotting\n",
        "    writer = SummaryWriter(f\"logs/gan1\")\n",
        "\n",
        "    if config.LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_CRITIC, critic, opt_critic, config.LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    gen.train()\n",
        "    critic.train()\n",
        "\n",
        "    tensorboard_step = 0\n",
        "    # start at step that corresponds to img size that we set in config\n",
        "    step = int(log2(config.START_TRAIN_AT_IMG_SIZE / 4))\n",
        "    for num_epochs in config.PROGRESSIVE_EPOCHS[step:]:\n",
        "        alpha = 1e-5  # start with very low alpha\n",
        "        loader, dataset = get_loader(4 * 2 ** step)  # 4->0, 8->1, 16->2, 32->3, 64 -> 4\n",
        "        print(f\"Current image size: {4 * 2 ** step}\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "            tensorboard_step, alpha = train_fn(\n",
        "                critic,\n",
        "                gen,\n",
        "                loader,\n",
        "                dataset,\n",
        "                step,\n",
        "                alpha,\n",
        "                opt_critic,\n",
        "                opt_gen,\n",
        "                tensorboard_step,\n",
        "                writer,\n",
        "                scaler_gen,\n",
        "                scaler_critic,\n",
        "            )\n",
        "\n",
        "            if config.SAVE_MODEL:\n",
        "                save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n",
        "                save_checkpoint(critic, opt_critic, filename=config.CHECKPOINT_CRITIC)\n",
        "\n",
        "        step += 1  # progress to the next img size\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H7zaX2OY2qL",
        "outputId": "dab5c38d-ceab-4447-8b62-12c1f37b024e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current image size: 256\n",
            "Epoch [1/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/18 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "100%|██████████| 18/18 [00:27<00:00,  1.51s/it, gp=0.449, loss_critic=-18.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [2/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:23<00:00,  1.31s/it, gp=0.441, loss_critic=-3.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [3/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:23<00:00,  1.31s/it, gp=0.398, loss_critic=24.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [4/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 15/18 [00:20<00:03,  1.26s/it, gp=0.462, loss_critic=7.1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UybHHCAmaEZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}